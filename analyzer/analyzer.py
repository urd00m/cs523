"""
Entrypoint for the analysis component. The analyzer is responsible of:
1. Loading the target binary
2. Running the scanner to find potential gadgets
3. Run analyzer on each gadget (if not done during scanning)
"""

import argparse
import yaml
import pickle
import angr
import claripy.ast.base
import tqdm
import logging

from .scanner.scanner import Scanner
from .analysis.pipeline import AnalysisPipeline
from .shared.logger import *
from .shared.config import *
from .asmprinter.asmprinter import *


l = get_logger("MAIN")
l_verbose = get_logger("MAIN_VERBOSE")

def load_config(config_file):
    """
    Read the YAML configuration.
    """
    if config_file:
        with open(config_file, "r") as f:
            config = yaml.safe_load(f)
        if not ('controlled_registers' in config or 'controlled_stack' in config):
            l.critical("Invalid config file!")
    else:
        l.info("No config provided, using default config")
        config = {'controlled_registers': ['rax', 'rbx', 'rdi', 'rsi', 'rdx',
                                           'rcx', 'r8', 'r9', 'r10', 'r11',
                                           'r12', 'r13', 'r14', 'r15']}

    init_config(config)


def load_angr_project(binary_file: str, base_address, use_pickle) -> angr.Project:
    """
    Load angr project from a pickle, or create one if it does not exist.
    """
    if use_pickle:
        pickle_file = binary_file + '.angr'

        try:
            f = open(pickle_file, "rb")
            proj = pickle.load(f)
        except:
            proj = angr.Project(
                binary_file, auto_load_libs=False, main_opts={"base_addr": base_address})
            f = open(pickle_file, "wb")
            pickle.dump(proj, f)
            f.close()
    else:
        proj = angr.Project(
            binary_file, auto_load_libs=False, main_opts={"base_addr": base_address})

    return proj

def analyse_gadget(proj, gadget_address, name, csv_filename, tfp_csv_filename, asm_folder):
    """
    Run the scanner from a single entrypoint and analyze the potential transmissions
    found at symbolic-execution time.
    """

    # Step 1. Initialize the analyzer
    analysis_pipeline = AnalysisPipeline(name=name, gadget_address=gadget_address, proj=proj,
                    asm_folder=asm_folder, csv_filename=csv_filename,
                    tfp_csv_filename=tfp_csv_filename)

    # Step 2. Analyze the code snippet with angr.
    l.info(f"Analyzing gadget at address {hex(gadget_address)}...")
    s = Scanner(analysis_pipeline=analysis_pipeline)
    s.run(proj, gadget_address)

    l.info(f"Found {len(s.transmissions)} potential transmissions.")
    l.info(f"Found {len(s.calls)} potential tainted function pointers.")

    # Step 3. Analyze found gadgets (if not analyzed during scanning)
    if not global_config['AnalyzeDuringScanning']:

        for t in s.transmissions:
            analysis_pipeline.analyze_transmission(t)

        for tfp in s.calls:
            analysis_pipeline.analyze_tainted_function_pointer(tfp)

    l.info(f"Outputted {analysis_pipeline.n_final_transmissions} transmissions.")
    l.info(f"Outputted {analysis_pipeline.n_final_tainted_function_pointers} tainted function pointers.")
    
def run(binary, config_file, base_address, gadget_address, gadget_name, cache_project, csv_filename="", tfp_csv_filename="", asm_folder=""):
    """
    Run the analyzer on a binary.
    """
    # Disable Angr outputs
    logging.getLogger('angr').setLevel('ERROR')

    # Simplify how symbols get printed.
    claripy.ast.base._unique_names = False

    load_config(config_file)

    if global_config["LogLevel"] == 0:
        disable_logging()
    elif global_config["LogLevel"] == 1:
        disable_logging(keep_main=True)

    # Prepare angr project.
    l.info("Loading angr project...")
    proj   = load_angr_project(binary, base_address, cache_project)
    
    # run 
    analyse_gadget(proj, gadget_address, gadget_name, csv_filename, tfp_csv_filename, asm_folder)

# This code is generated by ChatGPT 
def parse_args():
    """
    Parse command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Run analyzer on binary.")
    
    # Add arguments
    parser.add_argument('binary', help="Path to the binary to analyze.")
    parser.add_argument('config_file', help="Path to the configuration file.")
    parser.add_argument('base_address', help="Base address for the analysis.")
    parser.add_argument('gadget_address', help="Gadget address")
    parser.add_argument('gadget_name', help="Gadget name")
    # always cache the project
    
    # Optional arguments
    parser.add_argument('--csv_filename', default="", help="Path to the CSV file for results.")
    parser.add_argument('--tfp_csv_filename', default="", help="Path to the TFP CSV file for results.")
    parser.add_argument('--asm_folder', default="", help="Directory for ASM files.")
    
    return parser.parse_args()

if __name__ == "__main__":
    # Parse command-line arguments
    args = parse_args()

    # Call the run function with parsed arguments
    run(args.binary, args.config_file, args.base_address, int(args.gadget_address, 16), args.gadget_name, True, args.csv_filename, args.tfp_csv_filename, args.asm_folder)